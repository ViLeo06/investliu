"""
ä¸»æ•°æ®ç”Ÿæˆå™¨
æ•´åˆæ‰€æœ‰æ¨¡å—ï¼Œç”Ÿæˆé™æ€JSONæ•°æ®æ–‡ä»¶
"""

import os
import sys
import json
import logging
from datetime import datetime
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from data_processor.stock_data_fetcher import StockDataFetcher
from data_processor.stock_analyzer import StockAnalyzer

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class DataGenerator:
    def __init__(self, output_dir="static_data"):
        self.output_dir = output_dir
        self.fetcher = StockDataFetcher()
        self.analyzer = StockAnalyzer()
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)
    
    def generate_all_data(self):
        """ç”Ÿæˆæ‰€æœ‰é™æ€æ•°æ®æ–‡ä»¶"""
        try:
            logger.info("å¼€å§‹ç”Ÿæˆé™æ€æ•°æ®æ–‡ä»¶...")
            
            # 1. è·å–å¸‚åœºæŒ‡æ•°æ•°æ®
            logger.info("è·å–å¸‚åœºæŒ‡æ•°æ•°æ®...")
            market_indices = self.fetcher.fetch_market_data()
            self._save_json(market_indices, 'market_indices.json')
            
            # 2. è·å–Aè‚¡æ•°æ®
            logger.info("è·å–Aè‚¡æ•°æ®...")
            a_stocks = self._get_stock_data_batch('A', pages=3)
            
            # 3. è·å–æ¸¯è‚¡æ•°æ®
            logger.info("è·å–æ¸¯è‚¡æ•°æ®...")
            hk_stocks = self._get_stock_data_batch('HK', pages=2)
            
            # 4. åˆå¹¶è‚¡ç¥¨æ•°æ®ç”¨äºå¸‚åœºæ‹©æ—¶åˆ†æ
            all_stocks = a_stocks + hk_stocks
            
            # 5. åˆ†æå¸‚åœºæ‹©æ—¶
            logger.info("åˆ†æå¸‚åœºæ‹©æ—¶...")
            market_timing = self.analyzer.analyze_market_timing(market_indices, all_stocks)
            self._save_json(market_timing, 'market_timing.json')
            
            # 6. åˆ†æAè‚¡æ•°æ®
            logger.info("åˆ†æAè‚¡æ•°æ®...")
            analyzed_a_stocks = self.analyzer.analyze_stocks(a_stocks, 'A')
            
            # 7. ç”ŸæˆAè‚¡æ¨è
            logger.info("ç”ŸæˆAè‚¡æ¨è...")
            a_recommendations = self.analyzer.generate_recommendations(analyzed_a_stocks)
            self._save_json(a_recommendations, 'stocks_a_recommendations.json')
            
            # 8. åˆ†ææ¸¯è‚¡æ•°æ®
            logger.info("åˆ†ææ¸¯è‚¡æ•°æ®...")
            analyzed_hk_stocks = self.analyzer.analyze_stocks(hk_stocks, 'HK')
            
            # 9. ç”Ÿæˆæ¸¯è‚¡æ¨è
            logger.info("ç”Ÿæˆæ¸¯è‚¡æ¨è...")
            hk_recommendations = self.analyzer.generate_recommendations(analyzed_hk_stocks)
            self._save_json(hk_recommendations, 'stocks_hk_recommendations.json')
            
            # 10. ç”ŸæˆæŠ•èµ„ç»„åˆå»ºè®®
            logger.info("ç”ŸæˆæŠ•èµ„ç»„åˆå»ºè®®...")
            # ä½¿ç”¨åˆ†æåçš„è‚¡ç¥¨æ•°æ®
            all_analyzed_stocks = analyzed_a_stocks + analyzed_hk_stocks
            portfolio = self.analyzer.assess_portfolio_risk(all_analyzed_stocks)
            self._save_json({'risk_level': portfolio, 'suggestions': []}, 'portfolio_suggestion.json')
            
            # 11. ç”Ÿæˆæ±‡æ€»æ•°æ®
            logger.info("ç”Ÿæˆæ±‡æ€»æ•°æ®...")
            summary = self._generate_summary(market_timing, a_recommendations, hk_recommendations, {'risk_level': portfolio, 'suggestions': []})
            self._save_json(summary, 'summary.json')
            
            # 12. ç”Ÿæˆå®Œæ•´çš„è‚¡ç¥¨åˆ—è¡¨ï¼ˆåˆ†é¡µï¼‰
            self._generate_stock_lists(analyzed_a_stocks, analyzed_hk_stocks)
            
            logger.info("æ‰€æœ‰æ•°æ®æ–‡ä»¶ç”Ÿæˆå®Œæˆï¼")
            return True
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ•°æ®æ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def _get_stock_data_batch(self, market_type, pages=3):
        """æ‰¹é‡è·å–è‚¡ç¥¨æ•°æ®"""
        try:
            logger.info(f"è·å–{market_type}è‚¡æ•°æ®...")
            
            if market_type == 'A':
                stocks = self.fetcher.fetch_a_stocks()
            elif market_type == 'HK':
                stocks = self.fetcher.fetch_hk_stocks()
            else:
                return []
            
            if stocks:
                logger.info(f"è·å–åˆ°{len(stocks)}åª{market_type}è‚¡")
                return stocks
            else:
                logger.warning(f"æœªè·å–åˆ°{market_type}è‚¡æ•°æ®")
                return []
                
        except Exception as e:
            logger.error(f"è·å–{market_type}è‚¡æ•°æ®å¤±è´¥: {e}")
            return []
    
    def _generate_summary(self, market_timing, a_recommendations, hk_recommendations, portfolio):
        """ç”Ÿæˆæ±‡æ€»æ•°æ®"""
        return {
            'update_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'market_status': {
                'sentiment': market_timing.get('market_sentiment', 'neutral'),
                'recommended_position': market_timing.get('recommended_position', 0.5),
                'main_signals': market_timing.get('signals', [])[:3]
            },
            'recommendations_count': {
                'a_stocks': len(a_recommendations) if isinstance(a_recommendations, list) else 0,
                'hk_stocks': len(hk_recommendations) if isinstance(hk_recommendations, list) else 0,
                'total': (len(a_recommendations) if isinstance(a_recommendations, list) else 0) + (len(hk_recommendations) if isinstance(hk_recommendations, list) else 0)
            },
            'top_picks': {
                'a_stocks': a_recommendations[:5] if isinstance(a_recommendations, list) and a_recommendations else [],
                'hk_stocks': hk_recommendations[:5] if isinstance(hk_recommendations, list) and hk_recommendations else []
            },
            'portfolio_risk': portfolio.get('risk_level', 'medium'),
            'investment_suggestions': portfolio.get('suggestions', [])[:3],
            'version': '1.0'
        }
    
    def _generate_stock_lists(self, a_stocks, hk_stocks):
        """ç”Ÿæˆå®Œæ•´çš„è‚¡ç¥¨åˆ—è¡¨ï¼ˆåˆ†é¡µï¼‰"""
        # Aè‚¡åˆ—è¡¨åˆ†é¡µ
        self._paginate_and_save(a_stocks, 'stocks_a_page', page_size=50)
        
        # æ¸¯è‚¡åˆ—è¡¨åˆ†é¡µ  
        self._paginate_and_save(hk_stocks, 'stocks_hk_page', page_size=50)
        
        # ç”Ÿæˆåˆ†é¡µç´¢å¼•
        a_pages = (len(a_stocks) + 49) // 50  # å‘ä¸Šå–æ•´
        hk_pages = (len(hk_stocks) + 49) // 50
        
        pagination_info = {
            'a_stocks': {
                'total_count': len(a_stocks),
                'total_pages': a_pages,
                'page_size': 50
            },
            'hk_stocks': {
                'total_count': len(hk_stocks),
                'total_pages': hk_pages,
                'page_size': 50
            },
            'update_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        self._save_json(pagination_info, 'pagination_info.json')
    
    def _paginate_and_save(self, stocks, filename_prefix, page_size=50):
        """åˆ†é¡µä¿å­˜è‚¡ç¥¨åˆ—è¡¨"""
        for i in range(0, len(stocks), page_size):
            page_num = i // page_size + 1
            page_stocks = stocks[i:i + page_size]
            
            filename = f"{filename_prefix}_{page_num}.json"
            self._save_json(page_stocks, filename)
    
    def _save_json(self, data, filename):
        """ä¿å­˜JSONæ–‡ä»¶"""
        try:
            filepath = os.path.join(self.output_dir, filename)
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            logger.info(f"ä¿å­˜æ–‡ä»¶: {filepath}")
        except Exception as e:
            logger.error(f"ä¿å­˜æ–‡ä»¶å¤±è´¥ {filename}: {e}")
    
    def generate_config_file(self):
        """ç”Ÿæˆé…ç½®æ–‡ä»¶"""
        # å°è¯•ä»é…ç½®æ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡è·å–åŸºç¡€URL
        base_url = 'https://your-username.github.io/investliu'
        try:
            import config
            if hasattr(config, 'GITHUB_USERNAME') and hasattr(config, 'GITHUB_REPO'):
                base_url = f'https://{config.GITHUB_USERNAME}.github.io/{config.GITHUB_REPO}'
        except ImportError:
            import os
            github_username = os.getenv('GITHUB_USERNAME')
            github_repo = os.getenv('GITHUB_REPO', 'investliu')
            if github_username:
                base_url = f'https://{github_username}.github.io/{github_repo}'
        
        config = {
            'api_endpoints': {
                'base_url': base_url,
                'summary': '/static_data/summary.json',
                'market_timing': '/static_data/market_timing.json',
                'a_stocks_recommendations': '/static_data/stocks_a_recommendations.json',
                'hk_stocks_recommendations': '/static_data/stocks_hk_recommendations.json',
                'portfolio': '/static_data/portfolio_suggestion.json',
                'pagination': '/static_data/pagination_info.json'
            },
            'update_frequency': '24h',
            'cache_duration': '1h',
            'version': '1.0',
            'generated_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        self._save_json(config, 'config.json')
        
        # åŒæ—¶ç”Ÿæˆä¸€ä¸ªé€‚åˆå°ç¨‹åºçš„ç®€åŒ–é…ç½®
        miniprogram_config = {
            'baseUrl': config['api_endpoints']['base_url'],
            'endpoints': config['api_endpoints'],
            'updateTime': config['generated_time']
        }
        
        self._save_json(miniprogram_config, 'miniprogram_config.json')
    
    def validate_generated_data(self):
        """éªŒè¯ç”Ÿæˆçš„æ•°æ®æ–‡ä»¶"""
        required_files = [
            'summary.json',
            'market_timing.json', 
            'stocks_a_recommendations.json',
            'stocks_hk_recommendations.json',
            'portfolio_suggestion.json',
            'config.json'
        ]
        
        missing_files = []
        valid_files = []
        
        for filename in required_files:
            filepath = os.path.join(self.output_dir, filename)
            if os.path.exists(filepath):
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        json.load(f)  # éªŒè¯JSONæ ¼å¼
                    valid_files.append(filename)
                except json.JSONDecodeError:
                    logger.error(f"JSONæ ¼å¼é”™è¯¯: {filename}")
                    missing_files.append(filename)
            else:
                missing_files.append(filename)
        
        logger.info(f"éªŒè¯å®Œæˆ - æœ‰æ•ˆæ–‡ä»¶: {len(valid_files)}, ç¼ºå¤±æ–‡ä»¶: {len(missing_files)}")
        
        if missing_files:
            logger.warning(f"ç¼ºå¤±æ–‡ä»¶: {missing_files}")
            return False
        
        return True

def main():
    """ä¸»å‡½æ•°"""
    generator = DataGenerator()
    
    logger.info("=== è€åˆ˜æŠ•èµ„å†³ç­–ç³»ç»Ÿ - æ•°æ®ç”Ÿæˆå™¨ ===")
    
    # ç”Ÿæˆæ‰€æœ‰æ•°æ®
    success = generator.generate_all_data()
    
    if success:
        # ç”Ÿæˆé…ç½®æ–‡ä»¶
        generator.generate_config_file()
        
        # éªŒè¯æ•°æ®
        if generator.validate_generated_data():
            logger.info("âœ… æ•°æ®ç”Ÿæˆå®Œæˆä¸”éªŒè¯é€šè¿‡ï¼")
            logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {os.path.abspath(generator.output_dir)}")
            logger.info("ğŸš€ å¯ä»¥éƒ¨ç½²åˆ°GitHub Pagesäº†")
        else:
            logger.error("âŒ æ•°æ®éªŒè¯å¤±è´¥")
    else:
        logger.error("âŒ æ•°æ®ç”Ÿæˆå¤±è´¥")

if __name__ == "__main__":
    main()